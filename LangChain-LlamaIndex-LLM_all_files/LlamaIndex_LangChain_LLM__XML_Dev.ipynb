{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c5bf37a-90fe-4957-9931-845137ebf617",
     "showTitle": false,
     "title": ""
    },
    "id": "FRaf24J14PV-"
   },
   "outputs": [],
   "source": [
    "! pip install python-dotenv -q\n",
    "! pip install langchain -q\n",
    "! pip install openai -q\n",
    "! pip install llama-index -q\n",
    "! pip install PyPDF2 -q\n",
    "! pip install docx2txt -q\n",
    "! pip install faiss-cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f3001ce-7a4e-47a7-9e54-c5b78e0325d1",
     "showTitle": false,
     "title": ""
    },
    "id": "ThAh1hma4PWC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "import PyPDF2\n",
    "import docx2txt\n",
    "import re\n",
    "import openai\n",
    "import faiss\n",
    "from llama_index import (\n",
    "            GPTSimpleVectorIndex, \n",
    "            Document, \n",
    "            SimpleDirectoryReader, \n",
    "            PromptHelper, \n",
    "            LLMPredictor, \n",
    "            GPTFaissIndex, \n",
    "            ServiceContext\n",
    ")\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import OpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "#load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab662357-957a-481d-a1f6-41e251594709",
     "showTitle": false,
     "title": ""
    },
    "id": "IplrX3zC4PWD"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e7afe47-0b41-407a-9f23-cf7d873b8da6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# openai.api_type=os.getenv(\"OPENAI_API_TYPE\")\n",
    "# openai.api_base=os.getenv(\"OPENAI_API_BASE\") \n",
    "# openai.api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai.api_version=os.getenv(\"OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f638398-6e8e-402d-a2bc-3dd834101c35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain.document_loaders import TextLoader\n",
    "# import tiktoken\n",
    "\n",
    "\n",
    "# def create_embeddings(path):\n",
    "#     text_list = []\n",
    "#     docs = SimpleDirectoryReader(path).load_data() \n",
    "#     for document in docs:\n",
    "#         text_list.append(document.get_text())\n",
    "    \n",
    "#     response = openai.Embedding.create(\n",
    "#                     input=\"Your text string goes here\",\n",
    "#                     engine=\"embedding\"\n",
    "#     )\n",
    "#     embeddings = response['data'][0]['embedding']\n",
    "#     return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "032b4b32-b30f-4c92-97fd-a522cc5e0b8f",
     "showTitle": false,
     "title": ""
    },
    "id": "ouo2qqv54PWE"
   },
   "outputs": [],
   "source": [
    "def create_index(path):\n",
    "    # prompt helper properties\n",
    "    max_input = 4096\n",
    "    tokens = 200\n",
    "    chunk_size = 600 #for LLM, we need to define chunk size\n",
    "    max_chunk_overlap = 20\n",
    "    #SimpleVectorIndex properties\n",
    "    chunk_size_limit= 2000\n",
    "    d=1536\n",
    "    faiss_index = faiss.IndexFlatL2(d)\n",
    "\n",
    "    llm = OpenAI(temperature=0.2,model_name=\"text-davinci-003\", max_tokens=tokens) \n",
    "    #define prompt for OpenAI models.\n",
    "    promptHelper = PromptHelper(max_input,\n",
    "                            tokens,\n",
    "                            max_chunk_overlap,\n",
    "                            chunk_size)\n",
    "    #define LLM — there could be many models we can use, but in this example: \"text-davinci-003\"\n",
    "    llmPredictor = LLMPredictor(llm=llm)\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llmPredictor, \n",
    "                                                prompt_helper=promptHelper)\n",
    "    #load data — it will take all the .txtx files, if there are more than 1\n",
    "    docs = SimpleDirectoryReader(path).load_data() \n",
    "    print(docs)\n",
    "    #create vector index with FAISS\n",
    "    vectorIndex = GPTFaissIndex.from_documents(docs,\n",
    "                                            faiss_index=faiss_index,\n",
    "                                            service_context=service_context)   \n",
    "\n",
    "    vectorIndex.save_to_disk('vectorIndex.json')\n",
    "\n",
    "    return vectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018bdf0a-5702-4b32-90ed-a3fdb33afcfa",
     "showTitle": false,
     "title": ""
    },
    "id": "HuaxyxGd4PWF"
   },
   "outputs": [],
   "source": [
    "# To avoide redundant useage of API token, use saved vector index if the input documents are same as before.  \n",
    "data_path= '/Workspace/Repos/virajsunil.oke@ssc-spc.gc.ca/LangChain-LlamaIndex-LLM/LangChain-LlamaIndex-LLM_all_files/data/xml_sample_documents/'\n",
    "index = create_index(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfdadc76-347e-48d7-a4f7-85bc6e7e4ea7",
     "showTitle": false,
     "title": ""
    },
    "id": "6p-nPBKZ4PWG"
   },
   "source": [
    "#### Sample queries for XML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b532669d-23f4-43d7-9f13-1458d8449a37",
     "showTitle": false,
     "title": ""
    },
    "id": "Ebu0JqMS4PWG",
    "outputId": "d5e69460-87c2-456e-8bb9-c762c11c0052"
   },
   "outputs": [],
   "source": [
    "query_list = ['list out all the dates?']\n",
    "for query in query_list:\n",
    "    repsonse = index.query(query)\n",
    "    print(repsonse.response)\n",
    "    #answers.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6f44cb-52f3-4b89-a940-6263ff9c594a",
     "showTitle": false,
     "title": ""
    },
    "id": "blaMzfd04PWI"
   },
   "outputs": [],
   "source": [
    "repsonse = index.query('summarize all the documents separately', response_mode=\"tree_summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6bf3a19-c7b2-4ab3-ba91-0873f8869625",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(repsonse.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3e77f3d-202d-4a51-942a-bc4749f7f74a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LlamaIndex_LangChain_LLM__XML_Dev",
   "notebookOrigID": 4486251579480390,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
