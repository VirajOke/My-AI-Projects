{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9f8f30f7-4b7e-4a4b-bf4c-e05b28bd221d","showTitle":false,"title":""}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from etl import text_from_dir\n","from pretrained_summarization import get_summary\n","import nltk\n","import re\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.stem import WordNetLemmatizer\n","#from sklearn.decomposition import LatentDirichletAllocation\n","import gensim\n","from gensim.models.coherencemodel import CoherenceModel\n","#from nltk.stem import *\n","from gensim import corpora\n","from timeit import default_timer as timer"]},{"cell_type":"code","execution_count":14,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4577a5c2-b65f-483a-b9c2-487b61222777","showTitle":false,"title":""}},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\OkeV\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\OkeV\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\OkeV\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":15,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"19acca2e-f2e1-4277-bd77-01a49c5fbb2e","showTitle":false,"title":""}},"outputs":[],"source":["def preprocess_topic_text(final_data):\n","    lemmatize = WordNetLemmatizer()\n","    cnt_vec = CountVectorizer(stop_words = 'english')\n","    out_dict = dict()\n","    for key, value in final_data.items():\n","        result=[]\n","        for token in gensim.utils.simple_preprocess(value):\n","            if token not in gensim.parsing.preprocessing.STOPWORDS:\n","                result.append(token)\n","        tokens = [[lemmatize.lemmatize(word) for word in result]]\n","        #tokens = cnt_vec.fit_transform(tokens)\n","        out_dict[key] = tokens\n","    return out_dict"]},{"cell_type":"code","execution_count":16,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3c267d2a-bd59-4703-9a08-19a8396ed14d","showTitle":false,"title":""}},"outputs":[],"source":["#Try num_topics = [5:9]\n","def topic_model(out_dict):\n","    final_dict = dict()\n","    for keys, value in out_dict.items():\n","        dictionary = gensim.corpora.Dictionary(value)\n","        bow = [dictionary.doc2bow(doc) for doc in value]\n","        start = timer()\n","        lda_model = gensim.models.ldamodel.LdaModel(corpus = bow,\n","                                           id2word = dictionary,\n","                                           num_topics = 1, \n","                                           random_state = 100,\n","                                           update_every = 1,\n","                                           chunksize = 150,\n","                                           passes = 10,\n","                                           alpha = 'auto',\n","                                           per_word_topics = True)\n","        end = timer()\n","        final_dict[keys] = lda_model.print_topics()\n","        coherence_model_lda = CoherenceModel(model=lda_model, texts = value, dictionary= dictionary, coherence='c_v')\n","        coherence_lda = coherence_model_lda.get_coherence()\n","        print(f'Processing topics for {keys}')\n","        print(f'Topics extracted in {end-start:.2f} seconds')\n","        print(f'Coherence Score for {keys}: {coherence_lda:.2f}')\n","        print()\n"," \n","    return final_dict"]},{"cell_type":"code","execution_count":17,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"87283aa7-a0b3-419c-8df3-bc033f62e231","showTitle":false,"title":""}},"outputs":[],"source":["def display_results(topics):\n","    out_dict = dict()\n","    for indx, values in enumerate(topics.items()):\n","        for result in values[1]:\n","            text_score = re.sub(r'[^A-Za-z0-9.]', ' ', result[1])\n","            only_text = re.sub(r'[^A-Za-z]', ' ', text_score)\n","            only_scores = re.sub(r'[^0-9.]', ' ', text_score)\n","            text_tokens = word_tokenize(only_text)\n","            #score_tokens = word_tokenize(only_scores)\n","            #combined_list = zip(text_tokens,score_tokens)\n","            out_dict[values[0]] = list(text_tokens)\n","           \n","    return out_dict"]},{"cell_type":"code","execution_count":18,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cf9c7e76-2b33-4257-88d8-55527bc22b24","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["'def topics_to_df(out_dict):\\n    temp = []\\n    for indx, values in enumerate(out_dict.items()):\\n        locals()[\"final_df_\" +str(indx)] = pd.DataFrame(values[1], columns = [\\'key_word\\',\\'score\\'])\\n        locals()[\"final_df_\" +str(indx)] [\\'document_name\\'] = values[0]\\n        locals()[\"final_df_\" +str(indx)] = locals()[\"final_df_\" +str(indx)][[\\'document_name\\',\\'key_word\\',\\'score\\']]\\n        temp.append(locals()[\"final_df_\" +str(indx)])\\n        data = pd.concat(temp)\\n    data.reset_index(drop= \"index\" , inplace= True)    \\n    return data'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"def topics_to_df(out_dict):\n","    temp = []\n","    for indx, values in enumerate(out_dict.items()):\n","        locals()[\"final_df_\" +str(indx)] = pd.DataFrame(values[1], columns = ['key_word','score'])\n","        locals()[\"final_df_\" +str(indx)] ['document_name'] = values[0]\n","        locals()[\"final_df_\" +str(indx)] = locals()[\"final_df_\" +str(indx)][['document_name','key_word','score']]\n","        temp.append(locals()[\"final_df_\" +str(indx)])\n","        data = pd.concat(temp)\n","    data.reset_index(drop= \"index\" , inplace= True)    \n","    return data\"\"\""]},{"cell_type":"code","execution_count":19,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b41445f8-05c7-4519-aca8-9d17e02d7681","showTitle":false,"title":""}},"outputs":[],"source":["def get_topics(final_data):\n","    out_dict = preprocess_topic_text(final_data)\n","    topics = topic_model(out_dict)\n","    final_topics = display_results(topics)\n","    #topics_df = topics_to_df(final_topics)\n","    return final_topics, topics"]},{"cell_type":"code","execution_count":20,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"592a2c84-a3e3-4fbe-93d7-3cd37cd53de0","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing topics for 2020-11-16 GSA USAB meeting notes.docx\n","Topics extracted in 0.02 seconds\n","Coherence Score for 2020-11-16 GSA USAB meeting notes.docx: 0.34\n","\n","Processing topics for 2021-08-23 Doris Paquin (Spectrum) meeting notes.docx\n","Topics extracted in 0.01 seconds\n","Coherence Score for 2021-08-23 Doris Paquin (Spectrum) meeting notes.docx: 0.23\n","\n","Processing topics for ebidm-dsai meeting notes 2022-01-21.docx\n","Topics extracted in 0.02 seconds\n","Coherence Score for ebidm-dsai meeting notes 2022-01-21.docx: 0.25\n","\n","Processing topics for ICT-ACR meeting notes 2020-11-12.docx\n","Topics extracted in 0.01 seconds\n","Coherence Score for ICT-ACR meeting notes 2020-11-12.docx: 0.25\n","\n","Processing topics for 2021-10-15 ESD assumptions meeting notes.txt\n","Topics extracted in 0.01 seconds\n","Coherence Score for 2021-10-15 ESD assumptions meeting notes.txt: 0.32\n","\n","Processing topics for 2022-06-15 Onyx demo from Curtis ONeil.txt\n","Topics extracted in 0.01 seconds\n","Coherence Score for 2022-06-15 Onyx demo from Curtis ONeil.txt: 0.38\n","\n"]}],"source":["input_folder = 'C:/Users/OkeV/Documents/GitHub/nlp-exploration-notebooks/text_summarization'\n","data_cleaning = True\n","\n","final_data = text_from_dir(input_folder, data_cleaning)\n","final_topics, topics = get_topics(final_data)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f82b0612-1f27-4622-8a84-d8a745989090","showTitle":false,"title":""}},"source":["#### Self note: \n","- The keywords generated by the topic model can be merged with the text summarization summaries."]},{"cell_type":"code","execution_count":21,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8da5be43-1c95-499a-a685-1fbb15888337","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["{'2020-11-16 GSA USAB meeting notes.docx': ['work',\n","  'john',\n","  'accessibility',\n","  'acr',\n","  'format',\n","  'testing',\n","  'risk',\n","  'vpat',\n","  'acrs',\n","  'standard'],\n"," '2021-08-23 Doris Paquin (Spectrum) meeting notes.docx': ['device',\n","  'spectrum',\n","  'data',\n","  'doris',\n","  'ecd',\n","  'server',\n","  'topology',\n","  'alert',\n","  'ticket',\n","  'switch'],\n"," 'ebidm-dsai meeting notes 2022-01-21.docx': ['br',\n","  'service',\n","  'time',\n","  'model',\n","  'loe',\n","  'phase',\n","  'data',\n","  'sastry',\n","  'value',\n","  'date'],\n"," 'ICT-ACR meeting notes 2020-11-12.docx': ['report',\n","  'issue',\n","  'risk',\n","  'page',\n","  'format',\n","  'sc',\n","  'common',\n","  'need',\n","  'developer',\n","  'text'],\n"," '2021-10-15 ESD assumptions meeting notes.txt': ['ticket',\n","  'service',\n","  'hour',\n","  'desk',\n","  'incident',\n","  'time',\n","  'ecd',\n","  'email',\n","  'sr',\n","  'desc'],\n"," '2022-06-15 Onyx demo from Curtis ONeil.txt': ['template',\n","  'partner',\n","  'email',\n","  'agent',\n","  'ticket',\n","  'incident',\n","  'create',\n","  'fill',\n","  'description',\n","  'ci']}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["final_topics"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e5a1b9a1-33c1-41bc-8038-9d1997345348","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#topics_df"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"topic_modeling","notebookOrigID":1979306900758287,"widgets":{}},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"9ba45a1fceae5df0b0ec0034669bc91c2e83c651d072a7e1ae40b9002f84b104"}}},"nbformat":4,"nbformat_minor":0}
